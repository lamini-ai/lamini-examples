# Playground

An important first step to building a new LLM is setting up an interface for experimentation with new users.
These tutorials will teach you how to call the LLM programitcally:

1. [Python Client](python_client/python_client.md) - Learn how to call the LLM from python.
2. [React](react_llm_playground/playground.md) - Learn how to call the LLM from a react web app similar to ChatGPT.
3. [Slackbot](slackbot/slackbot.md) - Learn how to call the LLM from a slackbot.

Once you have your own LLM application running, you can share it with a small
number of initial developers or test users to understand their queries and get
feedback.

You also have full control over the app so you can start customizing it to meet
your needs.

# FAQ

Here are some common questions that may help you reason about the design of your
first LLM app.

1. Who are your intended users?

2. How will this application be deployed?

3. What data is available to train the LLM?

4. What data is available online vs offline?

5. What are the gaps between the out of the box
   performance of the LLM, and your requirements?

